{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/jeliusheneriko/live-streaming-tweeter?scriptVersionId=184113903\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-18T05:59:09.04546Z","iopub.execute_input":"2024-06-18T05:59:09.045882Z","iopub.status.idle":"2024-06-18T05:59:10.310818Z","shell.execute_reply.started":"2024-06-18T05:59:09.045847Z","shell.execute_reply":"2024-06-18T05:59:10.309741Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"! pip install --upgrade tweepy\n# from tweepy import Stream\n# from tweepy.streaming import StreamListener\n","metadata":{"execution":{"iopub.status.busy":"2024-06-18T05:59:10.313055Z","iopub.execute_input":"2024-06-18T05:59:10.313526Z","iopub.status.idle":"2024-06-18T05:59:18.753037Z","shell.execute_reply.started":"2024-06-18T05:59:10.313493Z","shell.execute_reply":"2024-06-18T05:59:18.751085Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install git+https://github.com/tweepy/tweepy.git","metadata":{"execution":{"iopub.status.busy":"2024-06-18T05:59:18.75895Z","iopub.execute_input":"2024-06-18T05:59:18.759306Z","iopub.status.idle":"2024-06-18T05:59:39.169323Z","shell.execute_reply.started":"2024-06-18T05:59:18.759268Z","shell.execute_reply":"2024-06-18T05:59:39.167541Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nfrom tweepy import Stream\nfrom tweepy import OAuthHandler\nfrom tweepy.streaming import StreamListener\nimport json\nimport boto3\nfrom datetime import date\nimport uuid\n\n# Handling secretes \n\nfrom kaggle_secrets import UserSecretsClient\napi_key = UserSecretsClient()\nacess_token = user_secrets.get_secret(\"acess_token\")\nacess_tokenCkey = user_secrets.get_secret(\"acess_tokenCkey\")\napi_ckey = user_secrets.get_secret(\"api_ckey\")\napi_key = user_secrets.get_secret(\"api_key\")\nbearer_token = user_secrets.get_secret(\"bearer_token\")\n#consumer key, consumer secret, access token, access secret.\n\nckey= api_key\ncsecret= api_ckey\natoken= acess_token\nasecret= acess_tokenCkey\n\n\n\ns3 = boto3.client('s3')\n\n\nclass listener(StreamListener):\n\n    def on_data(self, data):\n        all_data = json.loads(data)\n\n        tweet = all_data[\"text\"]\n        #print(all_data)\n        username = all_data[\"user\"][\"screen_name\"]\n        print(username)\n        \n        values = {\"uname\":username,\"id\":all_data['id'],\"data\":tweet} \n        #values=json.dumps(values)\n        today = date.today()\n        today = today.strftime(\"%Y/%m/%d\")\n        u_id=uuid.uuid1()\n        key_name= today+'/'+ str(u_id)+'_'+username+'.json'\n        s3.put_object(Body=str(values), Bucket='twitter-s3', Key=key_name)\n\n\n        return True\n\n    def on_error(self, status):\n        print(status)\n\nauth = OAuthHandler(ckey, csecret)\nauth.set_access_token(atoken, asecret)\n\ntwitterStream = Stream(auth, listener())\ntags = ['#emo']\ntwitterStream.filter(track=tags)\n","metadata":{"execution":{"iopub.status.busy":"2024-06-18T05:59:39.173737Z","iopub.execute_input":"2024-06-18T05:59:39.174172Z","iopub.status.idle":"2024-06-18T05:59:39.923239Z","shell.execute_reply.started":"2024-06-18T05:59:39.174131Z","shell.execute_reply":"2024-06-18T05:59:39.920752Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tweepy\nfrom textblob import TextBlob\nimport pandas as pd \nimport numpy as np\nimport re \nimport matplotlib.pyplot as plt\nplt.style.use('fivethirtyeight')","metadata":{"execution":{"iopub.status.busy":"2024-06-18T05:59:39.924315Z","iopub.status.idle":"2024-06-18T05:59:39.924916Z","shell.execute_reply.started":"2024-06-18T05:59:39.924587Z","shell.execute_reply":"2024-06-18T05:59:39.924621Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# impoting the credentials\n# Here I was required to enter the login credentials from the csv or any way of hiding it\n","metadata":{"execution":{"iopub.status.busy":"2024-06-18T05:59:39.926737Z","iopub.status.idle":"2024-06-18T05:59:39.927119Z","shell.execute_reply.started":"2024-06-18T05:59:39.926936Z","shell.execute_reply":"2024-06-18T05:59:39.926952Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Handling secretes \n\nfrom kaggle_secrets import UserSecretsClient\napi_key = UserSecretsClient()\nacess_token = user_secrets.get_secret(\"acess_token\")\nacess_tokenCkey = user_secrets.get_secret(\"acess_tokenCkey\")\napi_ckey = user_secrets.get_secret(\"api_ckey\")\napi_key = user_secrets.get_secret(\"api_key\")\nbearer_token = user_secrets.get_secret(\"bearer_token\")","metadata":{"execution":{"iopub.status.busy":"2024-06-18T05:59:39.929018Z","iopub.status.idle":"2024-06-18T05:59:39.929549Z","shell.execute_reply.started":"2024-06-18T05:59:39.929272Z","shell.execute_reply":"2024-06-18T05:59:39.929293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **The so called v1 tweeter and it errors**","metadata":{}},{"cell_type":"code","source":"import tweepy\nfrom textblob import TextBlob\n\n# Replace with your actual keys and tokens\napi_key = api_key\napi_secret_key = api_ckey\nbearer_token = bearer_token\naccess_token = acess_token\naccess_token_secret = acess_tokenCkey\n\n# Authenticate using OAuth 1.0a (User context)\nauth = tweepy.OAuthHandler(api_key, api_secret_key)\nauth.set_access_token(access_token, access_token_secret)\napi = tweepy.API(auth)\n\n# Define the search term and fetch tweets\nsearch_term = \"#Bitcoin -filter:retweets\"\ntweets = tweepy.Cursor(api.search_tweets, q=search_term, lang='en', tweet_mode='extended').items(100)\n\n# Analyze sentiment\nfor tweet in tweets:\n    text = tweet.full_text\n    blob = TextBlob(text)\n    sentiment = blob.sentiment\n    print(f\"Tweet: {text}\")\n    print(f\"Sentiment: {sentiment}\")\n    print()\n\n","metadata":{"execution":{"iopub.status.busy":"2024-06-18T05:59:39.931199Z","iopub.status.idle":"2024-06-18T05:59:39.93175Z","shell.execute_reply.started":"2024-06-18T05:59:39.931461Z","shell.execute_reply":"2024-06-18T05:59:39.931483Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **The so called v2**","metadata":{}},{"cell_type":"code","source":"import tweepy\nfrom textblob import TextBlob\n\n# Replace with your actual keys and tokens\napi_key = api_key\napi_secret_key = api_ckey\nbearer_token = bearer_token\naccess_token = acess_token\naccess_token_secret = acess_tokenCkey\n# Authenticate using Bearer Token for Twitter API v2\nclient = tweepy.Client(bearer_token=bearer_token)\n\n# Define the search term and fetch tweets\nsearch_term = \"#Bitcoin -is:retweet\"\nstart_time = \"2024-06-10T00:00:00Z\"\n\n# Fetch tweets\ntry:\n    tweets = client.search_recent_tweets(query=search_term, start_time=start_time, max_results=100, tweet_fields=['text'])\n\n    # Store the tweet texts\n    if tweets.data:\n        all_tweets = [tweet.text for tweet in tweets.data]\n        \n        # Analyze sentiment\n        for tweet in all_tweets:\n            blob = TextBlob(tweet)\n            sentiment = blob.sentiment\n            print(f\"Tweet: {tweet}\")\n            print(f\"Sentiment: {sentiment}\")\n            print()\n        \n        print(f\"Total tweets fetched: {len(all_tweets)}\")\n    else:\n        print(\"No tweets found\")\nexcept tweepy.TweepyException as e:\n    print(f\"Error: {e}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-06-18T05:59:39.933375Z","iopub.status.idle":"2024-06-18T05:59:39.933919Z","shell.execute_reply.started":"2024-06-18T05:59:39.933624Z","shell.execute_reply":"2024-06-18T05:59:39.933646Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Replace with your own keys and tokens\nconsumer_key = api_key \nconsumer_secret = api_ckey\nbearer_token = bearer_token\n\n# Authenticate using OAuth 2.0 Bearer Token\nauth = tweepy.AppAuthHandler(consumer_key, consumer_secret)\n\n# Initialize Tweepy API client\napi = tweepy.Client(auth=auth)\n\n# Example usage: Fetch recent tweets with a search term\nsearch_term = '#Bitcoin'\ntweets = api.search_recent_tweets(query=search_term, max_results=10, tweet_fields=['text'])\n\n# Print out the tweet texts\nfor tweet in tweets.data:\n    print(tweet.text)\n\n# Optionally, fetch user timeline\n# user_timeline = api.user_timeline(screen_name='twitter', count=10)\n\n# Close the API client connection\napi.close()","metadata":{"execution":{"iopub.status.busy":"2024-06-18T05:59:39.93583Z","iopub.status.idle":"2024-06-18T05:59:39.936538Z","shell.execute_reply.started":"2024-06-18T05:59:39.936239Z","shell.execute_reply":"2024-06-18T05:59:39.936266Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" ## **Then i decided to use the web scraping technique to get the tweets by any means**","metadata":{}},{"cell_type":"code","source":"! pip install snscrape","metadata":{"execution":{"iopub.status.busy":"2024-06-18T05:59:39.938275Z","iopub.status.idle":"2024-06-18T05:59:39.938872Z","shell.execute_reply.started":"2024-06-18T05:59:39.93854Z","shell.execute_reply":"2024-06-18T05:59:39.938575Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import snscrape.modules.twitter as snstweeter \nimport pandas as pd # This is for new working space \n\n# Specifiying the query \nquery = \"Bitcoin\"\n\nfor tweet in snstweeter.TwitterSearchScraper(query).get_items():\n    print(vars(tweet))\n    break","metadata":{"execution":{"iopub.status.busy":"2024-06-18T05:59:39.940404Z","iopub.status.idle":"2024-06-18T05:59:39.940861Z","shell.execute_reply.started":"2024-06-18T05:59:39.940601Z","shell.execute_reply":"2024-06-18T05:59:39.940617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **The above code gave me errors but its actually right (its just outdated by tweeters security layer**","metadata":{}},{"cell_type":"code","source":"tweets =[]\nlimit  = 100\nfor tweet in snstweeter.TwitterSearchScraper(query).get_items():\n    if len(tweet)==limit+1:\n        break\n    else:\n        tweets.append([tweet.date,tweet.user.username,tweet.content])\n    tweet_df = pd.DataFrame(tweets,columns=['Date','User','Tweet'])\ntweet_df","metadata":{"execution":{"iopub.status.busy":"2024-06-18T05:59:39.942819Z","iopub.status.idle":"2024-06-18T05:59:39.943263Z","shell.execute_reply.started":"2024-06-18T05:59:39.94305Z","shell.execute_reply":"2024-06-18T05:59:39.943067Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Also that failed *Due to security reasons established by tweeter***","metadata":{}},{"cell_type":"markdown","source":"## *The hustle and battle continued*","metadata":{}},{"cell_type":"code","source":"! pip install ntscraper","metadata":{"execution":{"iopub.status.busy":"2024-06-18T06:01:06.689405Z","iopub.execute_input":"2024-06-18T06:01:06.689956Z","iopub.status.idle":"2024-06-18T06:01:22.472833Z","shell.execute_reply.started":"2024-06-18T06:01:06.689921Z","shell.execute_reply":"2024-06-18T06:01:22.47113Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd \nfrom ntscraper import Nitter","metadata":{"execution":{"iopub.status.busy":"2024-06-18T06:01:22.47574Z","iopub.execute_input":"2024-06-18T06:01:22.476189Z","iopub.status.idle":"2024-06-18T06:01:22.742075Z","shell.execute_reply.started":"2024-06-18T06:01:22.476147Z","shell.execute_reply":"2024-06-18T06:01:22.740781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating the object for Nitter\nscrapper = Nitter()","metadata":{"execution":{"iopub.status.busy":"2024-06-18T06:01:22.743751Z","iopub.execute_input":"2024-06-18T06:01:22.744444Z","iopub.status.idle":"2024-06-18T06:02:11.998062Z","shell.execute_reply.started":"2024-06-18T06:01:22.744413Z","shell.execute_reply":"2024-06-18T06:02:11.996791Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# twitter = scrapper.get_tweets('stockstthatgo',mode='user',number=7)\ntwitter2 =scrapper.get_tweets('KremlinRussia_E',mode='user',number=80)","metadata":{"execution":{"iopub.status.busy":"2024-06-18T06:25:38.594855Z","iopub.execute_input":"2024-06-18T06:25:38.595283Z","iopub.status.idle":"2024-06-18T06:25:52.148985Z","shell.execute_reply.started":"2024-06-18T06:25:38.595249Z","shell.execute_reply":"2024-06-18T06:25:52.147795Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"twitter","metadata":{"execution":{"iopub.status.busy":"2024-06-18T06:02:17.237159Z","iopub.execute_input":"2024-06-18T06:02:17.237499Z","iopub.status.idle":"2024-06-18T06:02:17.254081Z","shell.execute_reply.started":"2024-06-18T06:02:17.237473Z","shell.execute_reply":"2024-06-18T06:02:17.252599Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"twitter2","metadata":{"execution":{"iopub.status.busy":"2024-06-18T06:30:37.725549Z","iopub.execute_input":"2024-06-18T06:30:37.726345Z","iopub.status.idle":"2024-06-18T06:30:37.767499Z","shell.execute_reply.started":"2024-06-18T06:30:37.726307Z","shell.execute_reply":"2024-06-18T06:30:37.766322Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Being the first achievement ðŸŽ©\n","metadata":{}},{"cell_type":"code","source":"def get_tweets(name,mode,no):\n    tweets = scrapper.get_tweets(name,modes =mode,number = no)\n    final_tweet = []\n    for tweet in tweets['tweets']:\n        data  = [tweet['link'],tweet['text'],tweet['stats']['likes'],tweet['stats']['comments']]\n        final_tweets.append(data)\n\n    data = pd.DataFrame(final_tweet,columns=['link','text','date','No_of_likes','No_of_Tweets'])\n    return data","metadata":{"execution":{"iopub.status.busy":"2024-06-18T06:23:33.219748Z","iopub.execute_input":"2024-06-18T06:23:33.220187Z","iopub.status.idle":"2024-06-18T06:23:33.228292Z","shell.execute_reply.started":"2024-06-18T06:23:33.220155Z","shell.execute_reply":"2024-06-18T06:23:33.226755Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}